<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>eks on apcj@f5 blog</title>
    <link>/tags/eks/</link>
    <description>Recent content in eks on apcj@f5 blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="/tags/eks/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kubernetes | Ephemeral Kubernetes Lab with IaC and GitOps</title>
      <link>/posts/ephemeral-kubernetes-lab-with-iac-and-gitops/</link>
      <pubDate>Wed, 08 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/posts/ephemeral-kubernetes-lab-with-iac-and-gitops/</guid>
      <description>I&amp;rsquo;ve been thinking of moving my Kubernetes lab into the cloud, but with cloud resource usage being scrutinized by the IT department, running them 24x7 the way I&amp;rsquo;m used to is a no-go. I need a setup that meets the following requirements:
 Simple to create and tear down Applications must be pre-deployed when the cluster is up, as close to &amp;ldquo;just the way I left it there last night&amp;rdquo; as possible cost $0 when the setup has been switched off  I eventually settled on the idea of an ephemeral Kubernetes lab environment using Infrastructure as Code (IaC) and GitOps practices, which I will cover in this post.</description>
      <content>&lt;p&gt;I&amp;rsquo;ve been thinking of moving my Kubernetes lab into the cloud, but with cloud resource usage being scrutinized by the IT department, running them 24x7 the way I&amp;rsquo;m used to is a no-go. I need a setup that meets the following requirements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simple to create and tear down&lt;/li&gt;
&lt;li&gt;Applications must be pre-deployed when the cluster is up, as close to &amp;ldquo;just the way I left it there last night&amp;rdquo; as possible&lt;/li&gt;
&lt;li&gt;cost $0 when the setup has been switched off&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I eventually settled on the idea of an ephemeral Kubernetes lab environment using &lt;a href=&#34;#infrastructure-as-code-using-terraform&#34;&gt;Infrastructure as Code (IaC)&lt;/a&gt; and &lt;a href=&#34;#k8s-resource-management-via-gitops-using-argo-cd&#34;&gt;GitOps&lt;/a&gt; practices, which I will cover in this post. You can follow along by cross referencing the code found here:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/leonseng/terraform-everything/tree/master/eks-gitops&#34;&gt;https://github.com/leonseng/terraform-everything/tree/master/eks-gitops&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;infrastructure-as-code-using-terraform&#34;&gt;Infrastructure as Code using Terraform&lt;/h1&gt;
&lt;p&gt;Starting with the Kubernetes cluster, using a managed Kubernetes offering makes sense for me as my current focus is on Kubernetes applications.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If cluster customization is of importance, one can deploy Kubernetes on the cloud computes using tools like &lt;a href=&#34;https://github.com/kubernetes/kops&#34;&gt;kops&lt;/a&gt; or &lt;a href=&#34;https://github.com/kubernetes-sigs/kubespray&#34;&gt;kubespray&lt;/a&gt;, similarly adopting IaC practices detailed below.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I went with &lt;a href=&#34;https://aws.amazon.com/eks/&#34;&gt;EKS&lt;/a&gt; as I am more familiar with AWS. An EKS cluster (or any other managed Kubernetes offerings in the public cloud) has a lot of dependencies on other cloud resources, such as computes, gateways, security policies and more. Rather than figuring out &lt;em&gt;when&lt;/em&gt; to create &lt;em&gt;what&lt;/em&gt;, &lt;a href=&#34;https://www.terraform.io/&#34;&gt;Terraform&lt;/a&gt; can be used to define all the cloud resources needed for a functional EKS cluster in a declarative manner. In addition, Terraform modules such as &lt;a href=&#34;https://registry.terraform.io/modules/terraform-aws-modules/vpc/aws/latest&#34;&gt;vpc&lt;/a&gt; and &lt;a href=&#34;https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/latest&#34;&gt;eks&lt;/a&gt; can be used to further abstract away the web of dependencies. All it takes is a couple of Terraform modules and some data sources to create the cluster, as seen here:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/leonseng/terraform-everything/blob/master/eks-gitops/eks.tf&#34;&gt;https://github.com/leonseng/terraform-everything/blob/master/eks-gitops/eks.tf&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With the cluster sorted, I turn my attention to deploying Kubernetes resources/applications in the cluster.&lt;/p&gt;
&lt;h1 id=&#34;k8s-resource-management-via-gitops-using-argo-cd&#34;&gt;K8s resource management via GitOps using Argo CD&lt;/h1&gt;
&lt;p&gt;It&amp;rsquo;s instinctive to start running &lt;code&gt;kubectl&lt;/code&gt; commands to deploy Kubernetes resources that make up your application in the cluster, but keeping track of them gets harder overtime. If the cluster is to be rebuilt on a regular basis, we&amp;rsquo;d best hope we have a record of what&amp;rsquo;s deployed in it, and what better option than storing the Kubernetes manifests in a Git repository where the IaC definitions are also stored. With the desired state of applications in Git, the next step is ensuring the cluster state reflects the desired state. This is where GitOps comes in.&lt;/p&gt;
&lt;p&gt;GitOps can be briefly described as an automated workflow that ensures the state of the cluster and its applications matches the desired state from the source of truth, or Git repositories in the case. GitOps achieves this with one of the two patterns below:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Changes are &lt;strong&gt;pushed&lt;/strong&gt; to the cluster&lt;/p&gt;
&lt;p&gt;Continuous deployment workflow applies the resource manifests on our cluster whenever there are changes in the Git repository. This can be done using simple Bash scripts, or orchestration tools like Ansible. A problem arises when there are multiple deployment workflows targeting the same cluster. As each workflow may not have a complete view of the cluster, it could lead to an inconsistent state in the cluster.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Changes are &lt;strong&gt;pulled&lt;/strong&gt; into the cluster&lt;/p&gt;
&lt;p&gt;Officially the preferred pattern in &lt;a href=&#34;https://opengitops.dev/blog/1.0-announcement/&#34;&gt;OpenGitOps v1.0.0&lt;/a&gt; - an agent in the cluster continuously polls the desired state from a remote Git repository, and applies the changes in the cluster. &lt;a href=&#34;https://argo-cd.readthedocs.io/en/stable/%5D&#34;&gt;Argo CD&lt;/a&gt; and &lt;a href=&#34;https://fluxcd.io/docs/&#34;&gt;Flux&lt;/a&gt; are two popular GitOps tools that employs this pattern.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For this article, I will be using Argo CD, mainly for its explicit support for the &lt;a href=&#34;#the-one-app-to-rule-them-all&#34;&gt;App of Apps pattern&lt;/a&gt; which I will cover in a section further down.&lt;/p&gt;
&lt;h2 id=&#34;argo-cd-applications&#34;&gt;Argo CD Applications&lt;/h2&gt;
&lt;p&gt;In Argo CD, a Kubernetes application are defined via an &lt;a href=&#34;https://argo-cd.readthedocs.io/en/stable/operator-manual/declarative-setup/#applications&#34;&gt;&lt;code&gt;Application&lt;/code&gt; custom resource (CR)&lt;/a&gt;. An &lt;code&gt;Application&lt;/code&gt; CR provides Argo CD with the following information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;source&lt;/strong&gt;: the Git repository, revision and path to where the collection of Kubernetes resource manifests are stored&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;destination&lt;/strong&gt;: the target cluster (Argo CD supports multi-cluster GitOps) and namespace to apply/deploy Kubernetes resource manifests in&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An &lt;code&gt;Application&lt;/code&gt; CR can be as simple as this:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: guestbook
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/argoproj/argocd-example-apps.git
    targetRevision: HEAD
    path: guestbook
  destination:
    server: https://kubernetes.default.svc
    namespace: guestbook
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The diagram below shows how an application is deployed with Argo CD:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/argocd-basic.png&#34; alt=&#34;Basic Argo CD workflow&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;User creates/modifies and uploads Kubernetes resource manifests (e.g. Deployment, ConfigMap, Service etc) for an application into a Git repository.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;manual step in cluster&lt;/strong&gt;) User deploys an &lt;code&gt;Application&lt;/code&gt; CR.&lt;/li&gt;
&lt;li&gt;Argo CD inspects &lt;code&gt;Application&lt;/code&gt; CR to discover the Git repository.&lt;/li&gt;
&lt;li&gt;Argo CD pulls the Kubernetes resource manifests from the Git repository.&lt;/li&gt;
&lt;li&gt;Argo CD applies/deploys the Kubernetes resource manifests into the target cluster and namespace per the &lt;code&gt;Application&lt;/code&gt; CR.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And just like that, our application deployment has been turned into code. Pretty cool! But we can do better&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;the-one-app-to-rule-them-all&#34;&gt;The One App To Rule Them All&lt;/h2&gt;
&lt;p&gt;The previous workflow still involves a manual step on the cluster - creating the &lt;code&gt;Application&lt;/code&gt; CR in the cluster. If the user forgets or makes a mistake, the state of the cluster will not reflect the desired state defined in the Git repository. In order to deal with such scenarios, let&amp;rsquo;s turn to the &lt;a href=&#34;https://argo-cd.readthedocs.io/en/stable/operator-manual/cluster-bootstrapping/#app-of-apps-pattern&#34;&gt;App of Apps pattern&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Remember that an &lt;code&gt;Application&lt;/code&gt; CR just points the agent to where the Kubernetes resource manifests are, there&amp;rsquo;s no limitation on what kind of resources it supports. Naturally, this can be extended to other &lt;code&gt;Application&lt;/code&gt; CRs! Here&amp;rsquo;s how it works:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/argocd-app-of-apps.png&#34; alt=&#34;Argo CD app of apps workflow&#34;&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s start with the &lt;!-- raw HTML omitted --&gt;&lt;strong&gt;red&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt; flow that shows the bootstrapping:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;User creates a bootstrap Git repository to store &lt;code&gt;Application&lt;/code&gt; CRs for the actual applications we want to deploy.&lt;/li&gt;
&lt;li&gt;User deploys a bootstrap &lt;code&gt;Application&lt;/code&gt; CR on the cluster.&lt;/li&gt;
&lt;li&gt;Argo CD inspects the bootstrap &lt;code&gt;Application&lt;/code&gt; CR to discover the bootstrap Git repository.&lt;/li&gt;
&lt;li&gt;Argo CD agent starts monitoring the Git repository for new &lt;code&gt;Application&lt;/code&gt; CRs.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once the cluster has been bootstrapped (which only has to be done once when the cluster is being set up), let&amp;rsquo;s go through the &lt;!-- raw HTML omitted --&gt;&lt;strong&gt;green&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt; flow to see how applications are deployed/modified:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;User creates/modifies and uploads Kubernetes resource manifests (e.g. Deployment, ConfigMap, Service etc) for an application into an application Git repository.&lt;/li&gt;
&lt;li&gt;User creates/modifies and uploads an &lt;code&gt;Application&lt;/code&gt; CR for the above application into the bootstrap Git repository.&lt;/li&gt;
&lt;li&gt;Argo CD discovers new &lt;code&gt;Application&lt;/code&gt; CR in the bootstrap Git repository.&lt;/li&gt;
&lt;li&gt;Argo CD deploys the &lt;code&gt;Application&lt;/code&gt; CR in the cluster, and from it, discover the application Git repository.&lt;/li&gt;
&lt;li&gt;Argo CD pulls the Kubernetes resource manifests from the application Git repository&lt;/li&gt;
&lt;li&gt;Argo CD applies the Kubernetes resource manifests into the target cluster and namespace per the &lt;code&gt;Application&lt;/code&gt; CR.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Using the App of Apps pattern means we only have to maintain the desired state of our applications through Git, and Argo CD would automatically apply the desired state in the cluster.&lt;/p&gt;
&lt;p&gt;Phew&amp;hellip; that was a lot to take in 😅. Hopefully we are now in the right head space to move on to the next section where we automate the bootstrapping via Terraform.&lt;/p&gt;
&lt;h2 id=&#34;terraforming-gitops&#34;&gt;Terraforming GitOps&lt;/h2&gt;
&lt;p&gt;To integrate this GitOps workflow and the App of Apps pattern with the &lt;a href=&#34;#infrastructure-as-code-with-terraform&#34;&gt;IaC&lt;/a&gt; definitions, we use Terraform to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Install Argo CD in the cluster&lt;/p&gt;
&lt;p&gt;I found two Terraform providers which can manage Kubernetes resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/kubernetes/latest&#34;&gt;kubernetes&lt;/a&gt; - officially supported by HashiCorp, but requires Kubernetes resources to be defined in the Terraform&amp;rsquo;s syntax HCL instead of YAML. It also does not support defining a CRD and any corresponding CRs within the same Terraform project, as the CRD won&amp;rsquo;t exist when Terraform is processing the CRs in the planning stage.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://registry.terraform.io/providers/gavinbunney/kubectl/latest&#34;&gt;kubectl&lt;/a&gt; - allows you to work in YAML and supports overwriting namespaces in the manifest. However, when performing &lt;code&gt;terraform destroy&lt;/code&gt;, it does not seem to wait for resources to be fully deleted before marking them as destroyed (see &lt;a href=&#34;https://github.com/gavinbunney/terraform-provider-kubectl/issues/109&#34;&gt;issue&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Neither of them are perfect, but I&amp;rsquo;m inclined to use the &lt;a href=&#34;https://registry.terraform.io/providers/hashicorp/kubernetes/latest&#34;&gt;kubernetes&lt;/a&gt; provider for the official support, and deviate when it doesn&amp;rsquo;t work.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bootstrap the cluster with an &lt;code&gt;Application&lt;/code&gt; CR to utilize the App of Apps pattern.&lt;/p&gt;
&lt;p&gt;As explained earlier, this &lt;code&gt;Application&lt;/code&gt; CR (see &lt;a href=&#34;https://github.com/leonseng/terraform-everything/blob/master/eks-gitops/bootstrap-app.yaml.tpl&#34;&gt;manifest&lt;/a&gt;) is responsible for defining the deployment of all other applications that we actually want running in our cluster. It simply points to a repository that looks something like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/leonseng/terraform-everything/tree/master/eks-gitops/demo/argocd-apps&#34;&gt;https://github.com/leonseng/terraform-everything/tree/master/eks-gitops/demo/argocd-apps&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;where there are two applications to be deployed - &lt;a href=&#34;https://github.com/leonseng/terraform-everything/tree/master/eks-gitops/demo/httpbin&#34;&gt;httpbin&lt;/a&gt; and &lt;a href=&#34;https://github.com/leonseng/terraform-everything/tree/master/eks-gitops/demo/nginx&#34;&gt;nginx&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The full Terraform file can be seen here:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/leonseng/terraform-everything/blob/master/eks-gitops/argocd.tf&#34;&gt;https://github.com/leonseng/terraform-everything/blob/master/eks-gitops/argocd.tf&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;finale&#34;&gt;Finale&lt;/h1&gt;
&lt;p&gt;With the Terraform files and application manifests in their respective Git repositories, we can kick off the deployment with the Terraform commands&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;terraform init
terraform apply -auto-approve
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And at the end of the day, shutting it down is as easy as running&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;terraform destroy -auto-approve
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Is it perfect? No. I need to be conscious of storing my application manifests in Git, which will slow me down. And occasionally, the destroy process fails due to some orphaned cloud resources (work in progress). But what I have now is an on/off button for my Kubernetes lab in the cloud, which should keep the IT department of my back 😁.&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
